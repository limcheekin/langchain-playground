{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "https://learn.deeplearning.ai/langchain/lesson/2/models,-prompts-and-parsers\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI API (custom one that enabled by `llama-cpp-python` with Wizard-Vicuna-13B-Uncensored-GGML model at the back)\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The answer to \"What is 1+1?\" is 2.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize for your unfortunate experience with your blender lid. It sounds like a frustrating situation. Is there anything I can do to assist you in this matter?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, max_tokens=1024)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for your unfortunate experience with your blender lid. It sounds like a frustrating situation. Is there anything I can do to assist you in this matter?\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr matey, I be sorry to hear 'bout yer troubles with yer blender. But if ye didn't put the lid on, it be no surprise that it got messy. Aye, we all make mistakes sometimes, but next time, remember ta keep a tight lid on things. Arrrgh!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The following information can be extracted from the given text:\n",
      "gift: False\n",
      "delivery_days: 2\n",
      "price_value: [\"It arrived in two days\", \"I think my wife liked it so much she was speechless.\"]\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, max_tokens=1024)\n",
    "response = chat(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 ms, sys: 1.58 ms, total: 26 ms\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here's an example code snippet that extracts the requested information from the given text:\n",
      "```python\n",
      "import re\n",
      "text = \"This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "# Define regular expressions to match the requested information\n",
      "gift_regex = r\"Was the item purchased as a gift for someone else? Answer (True|False) if yes, False if not or unknown.?\"\n",
      "delivery_days_regex = r\"How many days did it take for the productto arrive? If this information is not found, output -1.\"\n",
      "price_value_regex = r\"Extract any sentences about the value or price,and output them as a comma separated Python list.\"\n",
      "# Extract the requested information using regular expressions\n",
      "gift_match = re.search(gift_regex, text)\n",
      "delivery_days_match = re.search(delivery_days_regex, text)\n",
      "price_value_match = re.findall(price_value_regex, text)\n",
      "# Create a dictionary to store the extracted information\n",
      "info = {\n",
      " \"gift\": \"\",\n",
      " \"delivery_days\": \"-1\",\n",
      " \"price_value\": \"\"\n",
      "}\n",
      "# Extract and store the requested information\n",
      "if gift_match:\n",
      " info[\"gift\"] = \"True\" if re.search(r\"True\", str(gift_match.group())) else \"False\"\n",
      "if delivery_days_match:\n",
      " info[\"delivery_days\"] = str(delivery_days_match.group())\n",
      "if price_value_match:\n",
      " info[\"price_value\"] = \", \".join(str(x) for x in price_value_match)\n",
      "# Print the extracted information as a markdown code snippet\n",
      "print(\"```json\")\n",
      "print(\"{\")\n",
      "for key, value in info.items():\n",
      " if isinstance(value, bool):\n",
      " print(f\"{key}={value}\")\n",
      " elif isinstance(value, str):\n",
      " print(f\"{key}='{value}'\")\n",
      " else:\n",
      " print(f\"{key}={value[:-1]}\")\n",
      "print(\"}\")\n",
      "```\n",
      "Output:\n",
      "```json\n",
      "{\n",
      " \"gift\": \"True\",\n",
      " \"delivery_days\": \"-1\",\n",
      " \"price_value\": \"\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content) \n",
    "# Wizard-Vicuna-13B-Uncensored-GGML model doesn't support output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, max_tokens=1024)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello, I am Ava. How can I assist you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI:  Hello, I am Ava. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The answer to the question \"What is 1+1?\" is 2.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI:  Hello, I am Ava. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:  The answer to the question \"What is 1+1?\" is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Your name has not been provided, so Ava does not know the answer to this question.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI:  Hello, I am Ava. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:  The answer to the question \"What is 1+1?\" is 2.\n",
      "Human: What is my name?\n",
      "AI:  Your name has not been provided, so Ava does not know the answer to this question.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, my name is Andrew\\nAI:  Hello, I am Ava. How can I assist you today?\\nHuman: What is 1+1?\\nAI:  The answer to the question \"What is 1+1?\" is 2.\\nHuman: What is my name?\\nAI:  Your name has not been provided, so Ava does not know the answer to this question.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, max_tokens=1024)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello, I am Ava. How can I assist you today?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI:  Hello, I am Ava. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The answer to the question \"What is 1+1?\" is 2.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI:  The answer to the question \"What is 1+1?\" is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, but I do not have access to your name. Please provide more context so that I can assist you better.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System:  The human asks what's on the schedule for today, and the AI provides a detailed breakdown of the day's events including meetings, work on a project, lunch with a customer, and more.\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System:  The human asks what's on the schedule for today, and the AI provides a detailed breakdown of the day's events including meetings, work on a project, lunch with a customer, and more.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" One possible demonstration could be showing how the AI can analyze data from various sources and provide insights that help businesses make better decisions. For example, it could show how it can identify patterns in customer behavior or predict future trends based on historical data. Another option could be a live demo of the AI's natural language processing capabilities, such as answering questions or performing tasks like booking travel arrangements or ordering food.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System:  The human asks what's on the schedule for today, and the AI provides a detailed breakdown of the day's events including meetings, work on a project, lunch with a customer, and more. The human then asks what would be a good demo to show, and the AI suggests demonstrating the new feature that was added to the project yesterday.\\nAI:  One possible demonstration could be showing how the AI can analyze data from various sources and provide insights that help businesses make better decisions. For example, it could show how it can identify patterns in customer behavior or predict future trends based on historical data. Another option could be a live demo of the AI's natural language processing capabilities, such as answering questions or performing tasks like booking travel arrangements or ordering food.\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, max_tokens=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' One possible name for such a company could be \"Queen Size Linens\".'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, max_tokens=1024)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m The best name to describe a company that makes queen size sheet sets would be \"bedding manufacturer\" or \"linens producer\".\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m Sure, here's your description: \"The company specializes in producing high-quality queen size sheets and bedding essentials like pillowcases, comforters, and duvet covers.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure, here\\'s your description: \"The company specializes in producing high-quality queen size sheets and bedding essentials like pillowcases, comforters, and duvet covers.\"'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, max_tokens=1024)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le got mdiocre. La mousse ne tient pas, c'est bizarre. J'achte les mmes dans le commerce et le got est bien meilleur...\\nVieux lot ou contrefaon !?\",\n",
       " 'English_Review': '\"I find the taste mediocre. The foam doesn\\'t hold, it\\'s strange. I buy the same in the store and the taste is better...\"',\n",
       " 'summary': ' \"The quality of the coffee sold in the store is better than the one sampled at the caf.\"',\n",
       " 'followup_message': ' \"Le caf vendu dans la boutique a une meilleure qualit que celui essay au caf.\"'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Je trouve le got mdiocre. La mousse ne tient pas, c'est bizarre. J'achte les mmes dans le commerce et le got est bien meilleur...\\nVieux lot ou contrefaon !?\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\n To answer your question about black body radiation, we recommend using the \"physics\" prompt. However, if you revise your input to something like \"Can you explain how black body radiation works?\" or \"What is the relationship between temperature and black body radiation?\", it may lead to a better response from the language model.\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/output_parsers/json.py:32\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     json_obj \u001b[39m=\u001b[39m parse_json_markdown(text)\n\u001b[1;32m     33\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/output_parsers/json.py:25\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m parsed \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(json_str)\n\u001b[1;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m parsed\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/router/llm_router.py:96\u001b[0m, in \u001b[0;36mRouterOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     95\u001b[0m expected_keys \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdestination\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnext_inputs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 96\u001b[0m parsed \u001b[39m=\u001b[39m parse_and_check_json_markdown(text, expected_keys)\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(parsed[\u001b[39m\"\u001b[39m\u001b[39mdestination\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/output_parsers/json.py:34\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot invalid JSON object. Error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m expected_keys:\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chain\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is black body radiation?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:256\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/router/base.py:82\u001b[0m, in \u001b[0;36mMultiRouteChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     80\u001b[0m _run_manager \u001b[39m=\u001b[39m run_manager \u001b[39mor\u001b[39;00m CallbackManagerForChainRun\u001b[39m.\u001b[39mget_noop_manager()\n\u001b[1;32m     81\u001b[0m callbacks \u001b[39m=\u001b[39m _run_manager\u001b[39m.\u001b[39mget_child()\n\u001b[0;32m---> 82\u001b[0m route \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrouter_chain\u001b[39m.\u001b[39;49mroute(inputs, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m     84\u001b[0m _run_manager\u001b[39m.\u001b[39mon_text(\n\u001b[1;32m     85\u001b[0m     \u001b[39mstr\u001b[39m(route\u001b[39m.\u001b[39mdestination) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(route\u001b[39m.\u001b[39mnext_inputs), verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m route\u001b[39m.\u001b[39mdestination:\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/router/base.py:30\u001b[0m, in \u001b[0;36mRouterChain.route\u001b[0;34m(self, inputs, callbacks)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroute\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any], callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Route:\n\u001b[0;32m---> 30\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(inputs, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m Route(result[\u001b[39m\"\u001b[39m\u001b[39mdestination\u001b[39m\u001b[39m\"\u001b[39m], result[\u001b[39m\"\u001b[39m\u001b[39mnext_inputs\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/router/llm_router.py:60\u001b[0m, in \u001b[0;36mLLMRouterChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     56\u001b[0m _run_manager \u001b[39m=\u001b[39m run_manager \u001b[39mor\u001b[39;00m CallbackManagerForChainRun\u001b[39m.\u001b[39mget_noop_manager()\n\u001b[1;32m     57\u001b[0m callbacks \u001b[39m=\u001b[39m _run_manager\u001b[39m.\u001b[39mget_child()\n\u001b[1;32m     58\u001b[0m output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m     59\u001b[0m     Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict_and_parse(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs),\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/llm.py:238\u001b[0m, in \u001b[0;36mLLMChain.predict_and_parse\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39moutput_parser \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(result)\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/router/llm_router.py:113\u001b[0m, in \u001b[0;36mRouterOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed\n\u001b[1;32m    112\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m    114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParsing text\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m raised following error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Parsing text\n To answer your question about black body radiation, we recommend using the \"physics\" prompt. However, if you revise your input to something like \"Can you explain how black body radiation works?\" or \"What is the relationship between temperature and black body radiation?\", it may lead to a better response from the language model.\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Agents\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Using built in LangChain tools: DuckDuckGo search and Wikipedia\n",
    "* Defining your own tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20858.18s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from wikipedia)\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.0 in ./venv/lib/python3.10/site-packages (from wikipedia) (2.30.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.5.7)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
      "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=1be3bc73a7cfe27b9e7a66d4f304a4258f82e3446267ea614d4a0ad6d74da1ef\n",
      "  Stored in directory: /home/limcheekin/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1 wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output:  {\n",
      " \"action\": \"Calculator\",\n",
      " \"action_input\": \"What is 25% of 300?\"\n",
      "}\n",
      "\n",
      "### \u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m I apologize for the confusion. Here's a valid $JSON_BLOB that uses the Calculator tool to calculate 25% of 300:\n",
      "```\n",
      "{\n",
      " \"action\": \"Calculator\",\n",
      " \"action_input\": \"What is 25% of 300?\"\n",
      "}\n",
      "```\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format from LLM: To calculate 25% of a number, we need to find out what percentage it is and then multiply by 0.25. In this case, 25% of 300 is (0.25 * 300) = 75.\n```text\n25% of 300\n```\n...numexpr.evaluate(\"(0.25 * 300)\")...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# agent(\"What is the 25% of 300?\") doesn't works!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m agent(\u001b[39m\"\u001b[39;49m\u001b[39mCalculate the value of 25\u001b[39;49m\u001b[39m% o\u001b[39;49;00m\u001b[39mf 300.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:953\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 953\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    954\u001b[0m         name_to_tool_map,\n\u001b[1;32m    955\u001b[0m         color_mapping,\n\u001b[1;32m    956\u001b[0m         inputs,\n\u001b[1;32m    957\u001b[0m         intermediate_steps,\n\u001b[1;32m    958\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    961\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    962\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    963\u001b[0m         )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:820\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    818\u001b[0m         tool_run_kwargs[\u001b[39m\"\u001b[39m\u001b[39mllm_prefix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    821\u001b[0m         agent_action\u001b[39m.\u001b[39;49mtool_input,\n\u001b[1;32m    822\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    823\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    824\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    825\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_run_kwargs,\n\u001b[1;32m    826\u001b[0m     )\n\u001b[1;32m    827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     tool_run_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/tools/base.py:294\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    293\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_end(\n\u001b[1;32m    297\u001b[0m         \u001b[39mstr\u001b[39m(observation), color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    298\u001b[0m     )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/tools/base.py:266\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    265\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 266\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs)\n\u001b[1;32m    267\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    268\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(\u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m ToolException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_tool_error:\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/tools/base.py:409\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m new_argument_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\n\u001b[1;32m    410\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    411\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    412\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m new_argument_supported\n\u001b[1;32m    415\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    416\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:256\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:149\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    143\u001b[0m _run_manager\u001b[39m.\u001b[39mon_text(inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key])\n\u001b[1;32m    144\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m    145\u001b[0m     question\u001b[39m=\u001b[39minputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key],\n\u001b[1;32m    146\u001b[0m     stop\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m```output\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    147\u001b[0m     callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(),\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_llm_result(llm_output, _run_manager)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:112\u001b[0m, in \u001b[0;36mLLMMathChain._process_llm_result\u001b[0;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[1;32m    110\u001b[0m     answer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAnswer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m llm_output\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39mAnswer:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown format from LLM: \u001b[39m\u001b[39m{\u001b[39;00mllm_output\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer}\n",
      "\u001b[0;31mValueError\u001b[0m: unknown format from LLM: To calculate 25% of a number, we need to find out what percentage it is and then multiply by 0.25. In this case, 25% of 300 is (0.25 * 300) = 75.\n```text\n25% of 300\n```\n...numexpr.evaluate(\"(0.25 * 300)\")..."
     ]
    }
   ],
   "source": [
    "# agent(\"What is the 25% of 300?\") doesn't works!\n",
    "agent(\"Calculate the value of 25% of 300.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Here's your $JSON_BLOB:\n",
      "```\n",
      "{\n",
      " \"action\": Wikipedia,\n",
      " \"action_input\": Tom M. Mitchell CMU\n",
      "}\n",
      "```\n",
      "\n",
      "And here's the result of running that action:\n",
      "```\n",
      "Question: What book did Tom M. Mitchell write?\n",
      "Action: \n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output:  The book is called \"Machine Learning: A Guide to the Theory and Practice of Learning Machines\".\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Machine Learning: A Guide to the Theory and Practice of Learning Machines\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "result = agent(question) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: ` I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mSort these customers by \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mlast name and then first name \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mand print the output: \u001b[39;49m\u001b[39m{\u001b[39;49;00mcustomer_list\u001b[39m}\u001b[39;49;00m\u001b[39m\"\"\"\u001b[39;49m) \n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:256\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:953\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 953\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    954\u001b[0m         name_to_tool_map,\n\u001b[1;32m    955\u001b[0m         color_mapping,\n\u001b[1;32m    956\u001b[0m         inputs,\n\u001b[1;32m    957\u001b[0m         intermediate_steps,\n\u001b[1;32m    958\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    961\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    962\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    963\u001b[0m         )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:773\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    771\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    774\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:762\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m    763\u001b[0m         intermediate_steps,\n\u001b[1;32m    764\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    765\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m    766\u001b[0m     )\n\u001b[1;32m    767\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    443\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 444\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/mrkl/output_parser.py:42\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     38\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: text\u001b[39m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()}, text\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAction\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*?)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     43\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format: Missing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mAction:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m after \u001b[39m\u001b[39m'\u001b[39m\u001b[39mThought:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m         llm_output\u001b[39m=\u001b[39mtext,\n\u001b[1;32m     46\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\n\u001b[1;32m     49\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*Action\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*Input\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL\n\u001b[1;32m     50\u001b[0m ):\n\u001b[1;32m     51\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     52\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: ` I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.`"
     ]
    }
   ],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View detailed outputs of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [22.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \" I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 362,\n",
      "      \"completion_tokens\": 33,\n",
      "      \"total_tokens\": 395\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [22.31s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.\"\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [22.65s] Chain run errored with error:\n",
      "\u001b[0m\"OutputParserException('Could not parse LLM output: ` I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.`')\"\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: ` I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\n\u001b[1;32m      2\u001b[0m langchain\u001b[39m.\u001b[39mdebug\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mSort these customers by \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mlast name and then first name \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mand print the output: \u001b[39;49m\u001b[39m{\u001b[39;49;00mcustomer_list\u001b[39m}\u001b[39;49;00m\u001b[39m\"\"\"\u001b[39;49m) \n\u001b[1;32m      6\u001b[0m langchain\u001b[39m.\u001b[39mdebug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:256\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:145\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    146\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    147\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    148\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/chains/base.py:139\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    135\u001b[0m     inputs,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:953\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 953\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    954\u001b[0m         name_to_tool_map,\n\u001b[1;32m    955\u001b[0m         color_mapping,\n\u001b[1;32m    956\u001b[0m         inputs,\n\u001b[1;32m    957\u001b[0m         intermediate_steps,\n\u001b[1;32m    958\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    961\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    962\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    963\u001b[0m         )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:773\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    771\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    774\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:762\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m    763\u001b[0m         intermediate_steps,\n\u001b[1;32m    764\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    765\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m    766\u001b[0m     )\n\u001b[1;32m    767\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    443\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 444\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/agents/mrkl/output_parser.py:42\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     38\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: text\u001b[39m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()}, text\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAction\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*?)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     43\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format: Missing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mAction:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m after \u001b[39m\u001b[39m'\u001b[39m\u001b[39mThought:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m         llm_output\u001b[39m=\u001b[39mtext,\n\u001b[1;32m     46\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\n\u001b[1;32m     49\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*Action\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*Input\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL\n\u001b[1;32m     50\u001b[0m ):\n\u001b[1;32m     51\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     52\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: ` I think we should use the `sorted()` function to sort the list by last name and then first name. We can also print the output using a for loop.`"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your own tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "The agent will sometimes come to the wrong conclusion (agents are a work in progress!). \n",
    "\n",
    "If it does, please try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [185.54s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \" {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 424,\n",
      "      \"completion_tokens\": 1024,\n",
      "      \"total_tokens\": 1448\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [185.55s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:_Exception] [0.5810000000000001ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] [64.91s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1496,\n",
      "      \"completion_tokens\": 17,\n",
      "      \"total_tokens\": 1513\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] [64.92s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 7:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 7:tool:_Exception] [0.221ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] [61.86s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1533,\n",
      "      \"completion_tokens\": 17,\n",
      "      \"total_tokens\": 1550\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain] [61.86s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:_Exception] [0.609ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:LLMChain > 12:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:LLMChain > 12:llm:ChatOpenAI] [137.49s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1570,\n",
      "      \"completion_tokens\": 116,\n",
      "      \"total_tokens\": 1686\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:LLMChain] [137.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:tool:_Exception] [0.443ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:ChatOpenAI] [97.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1706,\n",
      "      \"completion_tokens\": 121,\n",
      "      \"total_tokens\": 1827\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain] [97.31s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:_Exception] [0.462ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:chain:LLMChain > 18:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:chain:LLMChain > 18:llm:ChatOpenAI] [77.05s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1843,\n",
      "      \"completion_tokens\": 17,\n",
      "      \"total_tokens\": 1860\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:chain:LLMChain] [77.05s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Please provide a valid $JSON_BLOB with the action and input values specified.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:tool:_Exception] [0.224ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 20:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 20:chain:LLMChain > 21:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 20:chain:LLMChain > 21:llm:ChatOpenAI] [81.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Answer the following questions as best you can. You have access to the following tools:\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1880,\n",
      "      \"completion_tokens\": 17,\n",
      "      \"total_tokens\": 1897\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 20:chain:LLMChain] [81.52s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Answer the following questions as best you can. You have access to the following tools:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 22:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 22:tool:_Exception] [0.444ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 23:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 23:chain:LLMChain > 24:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 23:chain:LLMChain > 24:llm:ChatOpenAI] [81.20s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Answer the following questions as best you can. You have access to the following tools:\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1917,\n",
      "      \"completion_tokens\": 17,\n",
      "      \"total_tokens\": 1934\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 23:chain:LLMChain] [81.20s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Answer the following questions as best you can. You have access to the following tools:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 25:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 25:tool:_Exception] [0.462ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain > 27:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain > 27:llm:ChatOpenAI] [148.37s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Answer the following questions as best you can. You have access to the following tools:\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1954,\n",
      "      \"completion_tokens\": 17,\n",
      "      \"total_tokens\": 1971\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain] [148.37s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Answer the following questions as best you can. You have access to the following tools:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 28:tool:_Exception] Entering Tool run with input:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 28:tool:_Exception] [0.194ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Invalid or incomplete response\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 29:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"whats the date today?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 29:chain:LLMChain > 30:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia, time\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: whats the date today?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output:  {\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_input\\\": \\\"\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"John Smith\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T16:59:57Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:00:56Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"New York City\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:02:55Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"World War II\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:05:54Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Elon Musk\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:08:53Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Facebook\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:11:52Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Bill Gates\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:14:51Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:17:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Amazon\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:20:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Microsoft\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:23:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Apple Inc.\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"action_input\\\": \\\"- 10 + 20\\\"\\n}\\n{\\n \\\"action\\\": \\\"time\\\",\\n \\\"action_output\\\": \\\"2023-04-28T17:26:50Z\\\"\\n}\\n{\\n \\\"action\\\": \\\"Wikipedia\\\",\\n \\\"action_input\\\": \\\"Google\\\"\\n}\\n{\\n \\\"action\\\": \\\"Calculator\\\",\\n \\\"\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\ntime: time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,\\n\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Please provide a valid $JSON_BLOB with the action and input values specified.\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:Could not parse LLM output: Answer the following questions as best you can. You have access to the following tools:\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 29:chain:LLMChain > 30:llm:ChatOpenAI] [92.32s] Chain run errored with error:\n",
      "\u001b[0m\"KeyboardInterrupt()\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 29:chain:LLMChain] [92.32s] Chain run errored with error:\n",
      "\u001b[0m\"KeyboardInterrupt()\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1027.61s] Chain run errored with error:\n",
      "\u001b[0m\"KeyboardInterrupt()\"\n",
      "exception on external access\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
