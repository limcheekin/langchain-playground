{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "920a3c1a",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "Constructing your language model application will likely involved choosing between many different options of prompts, models, and even chains to use. When doing so, you will want to compare these different options on different inputs in an easy, flexible, and intuitive way. \n",
    "\n",
    "LangChain provides the concept of a ModelLaboratory to test out and try different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5e8b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.238\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9e95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Modal, OpenAI\n",
    "from langchain.model_laboratory import ModelLaboratory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059e7ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling_temperature was transferred to model_kwargs.\n",
      "                    Please confirm that sampling_temperature is what you intended.\n",
      "max_length was transferred to model_kwargs.\n",
      "                    Please confirm that max_length is what you intended.\n",
      "include_prompt_in_result was transferred to model_kwargs.\n",
      "                    Please confirm that include_prompt_in_result is what you intended.\n"
     ]
    }
   ],
   "source": [
    "ct2_llm = Modal(\n",
    "    endpoint_url=os.environ[\"LLAMA2_13B_CHAT_CT2_URL\"], \n",
    "    sampling_temperature=0.0, \n",
    "    max_length=2042, \n",
    "    include_prompt_in_result=False)\n",
    "\n",
    "ggml_llm = OpenAI(\n",
    "    openai_api_base=os.environ[\"LLAMA2_13B_CHAT_GGML_URL\"], \n",
    "    temperature=0.0, \n",
    "    max_tokens=2042)\n",
    "\n",
    "llms = [ggml_llm, ct2_llm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd89f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF: https://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat/blob/main/model.py#L24\n",
    "DEFAULT_SYSTEM_PROMPT = \"You are a helpful assistant.\\nYou will try to answer user questions, but don't make up the answer if you don't have the answer.\\nYou will complete tasks by following user instructions.\"\n",
    "def get_prompt(message: str, chat_history: list[tuple[str, str]],\n",
    "               system_prompt: str) -> str:\n",
    "    texts = [f'[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n']\n",
    "    for user_input, response in chat_history:\n",
    "        texts.append(f'{user_input.strip()} [/INST] {response.strip()} </s><s> [INST] ')\n",
    "    texts.append(f'{message.strip()} [/INST]')\n",
    "    return ''.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab487f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure thing! I'd be happy to help answer your question about AI.\n",
      "\n",
      "AI stands for artificial intelligence, which refers to the ability of machines or computer programs to perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. AI systems use algorithms and data to make predictions, classify objects, and generate insights based on patterns they detect.\n",
      "\n",
      "There are many different types of AI, including:\n",
      "\n",
      "1. Narrow or weak AI, which is designed to perform a specific task, such as facial recognition or language translation.\n",
      "2. General or strong AI, which is designed to perform any intellectual task that a human can.\n",
      "3. Superintelligence, which is significantly more intelligent than the best human minds.\n",
      "4. Artificial general intelligence (AGI), which is a hypothetical AI system that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks, similar to human intelligence.\n",
      "AI has many applications in various industries, such as healthcare, finance, transportation, and education. It can be used for tasks such as image recognition, natural language processing, recommendation systems, and autonomous vehicles.\n",
      "\n",
      "I hope that helps! Do you have any other questions about AI?\n",
      "CPU times: user 23.8 ms, sys: 17 µs, total: 23.8 ms\n",
      "Wall time: 60 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(ggml_llm(get_prompt(\"What is AI?\", [], DEFAULT_SYSTEM_PROMPT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e09a57da",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/llms/base.py:429\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(prompt, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    424\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(prompt)\u001b[39m}\u001b[39;00m\u001b[39m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`generate` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    430\u001b[0m         [prompt],\n\u001b[1;32m    431\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m    434\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    435\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    436\u001b[0m     )\n\u001b[1;32m    437\u001b[0m     \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    438\u001b[0m     \u001b[39m.\u001b[39mtext\n\u001b[1;32m    439\u001b[0m )\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/llms/base.py:281\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    276\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         )\n\u001b[1;32m    278\u001b[0m     run_managers \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    279\u001b[0m         dumpd(\u001b[39mself\u001b[39m), prompts, invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    282\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/llms/base.py:225\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    224\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    226\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    227\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/llms/base.py:212\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    204\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    210\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 212\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    213\u001b[0m                 prompts,\n\u001b[1;32m    214\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    215\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    216\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    217\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    218\u001b[0m             )\n\u001b[1;32m    219\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    220\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    223\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/llms/base.py:604\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m    603\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 604\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    605\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    606\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/langchain/llms/modal.py:83\u001b[0m, in \u001b[0;36mModal._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m     82\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m---> 83\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m     84\u001b[0m     url\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint_url,\n\u001b[1;32m     85\u001b[0m     headers\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     86\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mContent-Type\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mapplication/json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     87\u001b[0m     },\n\u001b[1;32m     88\u001b[0m     json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams},\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[39myield\u001b[39;00m req\n\u001b[1;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    267\u001b[0m         req,\n\u001b[1;32m    268\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    269\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    270\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    271\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[1;32m    272\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    273\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madapter_kwargs,\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcookies, prepared_request, resp\u001b[39m.\u001b[39mraw)\n\u001b[1;32m    279\u001b[0m     \u001b[39m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(ct2_llm(\"What is AI?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cde09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lab = ModelLaboratory.from_llms(llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "What color is a flamingo?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {}}\n",
      "\u001b[36;1m\u001b[1;3mpink\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {}}\n",
      "\u001b[33;1m\u001b[1;3mFlamingos are typically pink in color.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lab.compare(\"What color is a flamingo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "248b652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=\"What is the capital of {state}?\", input_variables=[\"state\"])\n",
    "model_lab_with_prompt = ModelLaboratory.from_llms(llms, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f64377ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "New York\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {}}\n",
      "\u001b[36;1m\u001b[1;3malbany\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {}}\n",
      "\u001b[33;1m\u001b[1;3mThe capital of New York is Albany.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lab_with_prompt.compare(\"New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94159131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Answer based on context:\n",
      "\n",
      "1) Flutter is a framework for building cross-platform applications\n",
      "that uses the Dart programming language.\n",
      "To understand some differences between programming with Dart\n",
      "and programming with Javascript, \n",
      "see Learning Dart as a JavaScript Developer.\n",
      "2) Web FAQ\n",
      "\n",
      "Performance FAQ\n",
      "\n",
      "What is Flutter?\n",
      "\n",
      "Flutter is Google’s portable UI toolkit for crafting beautiful,\n",
      "natively compiled applications for mobile, web,\n",
      "and desktop from a single codebase.\n",
      "Flutter works with existing code,\n",
      "is used by developers and organizations around\n",
      "the world, and is free and open source.\n",
      "\n",
      "Who is Flutter for?\n",
      "\n",
      "For users, Flutter makes beautiful apps come to life.\n",
      "3) Flutter is a cross-platform UI toolkit that is designed to allow code reuse\n",
      "across operating systems such as iOS and Android, while also allowing\n",
      "applications to interface directly with underlying platform services. The goal\n",
      "is to enable developers to deliver high-performance apps that feel natural on\n",
      "different platforms, embracing differences where they exist while sharing as\n",
      "much code as possible.\n",
      "\n",
      "\n",
      "What is Flutter?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3m3)\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mThe most accurate answer is: Flutter is a framework for building cross-platform applications that uses the Dart programming language.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "Flutter is a framework for building cross-platform applications\n",
      "that uses the Dart programming language. Dart is a programming language\n",
      "that is used to build high-performance, scalable, and easy-to-use\n",
      "applications. Dart is a language that is built on top of the Dart VM,\n",
      "which is a native compiler that is designed to make the language\n",
      "easier to use.\n",
      "\n",
      "What is the Dart programming language?\n",
      "\n",
      "The Dart programming language is a language that is used to\n",
      "build high-performance, scalable, and easy-to-use\n",
      "applications. The Dart programming language is a\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Flutter is Google’s portable UI toolkit for crafting beautiful,\n",
      "natively compiled applications for mobile, web,\n",
      "and desktop from a single codebase.\n",
      "Flutter works with existing code,\n",
      "is used by developers and organizations around\n",
      "the world, and is free and open source.\n",
      "\n",
      "Who is Flutter for?\n",
      "\n",
      "For users, Flutter makes beautiful apps come to life.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\\\n",
    "1) Flutter is a framework for building cross-platform applications\n",
    "that uses the Dart programming language.\n",
    "To understand some differences between programming with Dart\n",
    "and programming with Javascript, \n",
    "see Learning Dart as a JavaScript Developer.\n",
    "2) Web FAQ\n",
    "\n",
    "Performance FAQ\n",
    "\n",
    "What is Flutter?\n",
    "\n",
    "Flutter is Google’s portable UI toolkit for crafting beautiful,\n",
    "natively compiled applications for mobile, web,\n",
    "and desktop from a single codebase.\n",
    "Flutter works with existing code,\n",
    "is used by developers and organizations around\n",
    "the world, and is free and open source.\n",
    "\n",
    "Who is Flutter for?\n",
    "\n",
    "For users, Flutter makes beautiful apps come to life.\n",
    "3) Flutter is a cross-platform UI toolkit that is designed to allow code reuse\n",
    "across operating systems such as iOS and Android, while also allowing\n",
    "applications to interface directly with underlying platform services. The goal\n",
    "is to enable developers to deliver high-performance apps that feel natural on\n",
    "different platforms, embracing differences where they exist while sharing as\n",
    "much code as possible.\n",
    "\"\"\"\n",
    "question = \"What is Flutter?\"\n",
    "prompt = f\"Answer based on context:\\n\\n{context}\\n\\n{question}\"\n",
    "model_lab.compare(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ce7d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Context: 1) Flutter is a framework for building cross-platform applications\n",
      "that uses the Dart programming language.\n",
      "To understand some differences between programming with Dart\n",
      "and programming with Javascript, \n",
      "see Learning Dart as a JavaScript Developer.\n",
      "2) Web FAQ\n",
      "\n",
      "Performance FAQ\n",
      "\n",
      "What is Flutter?\n",
      "\n",
      "Flutter is Google’s portable UI toolkit for crafting beautiful,\n",
      "natively compiled applications for mobile, web,\n",
      "and desktop from a single codebase.\n",
      "Flutter works with existing code,\n",
      "is used by developers and organizations around\n",
      "the world, and is free and open source.\n",
      "\n",
      "Who is Flutter for?\n",
      "\n",
      "For users, Flutter makes beautiful apps come to life.\n",
      "3) Flutter is a cross-platform UI toolkit that is designed to allow code reuse\n",
      "across operating systems such as iOS and Android, while also allowing\n",
      "applications to interface directly with underlying platform services. The goal\n",
      "is to enable developers to deliver high-performance apps that feel natural on\n",
      "different platforms, embracing differences where they exist while sharing as\n",
      "much code as possible.\n",
      "\n",
      "\n",
      "Question: What is Flutter?\n",
      "\n",
      "Answer:\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mFlutter is Google’s portable UI toolkit for crafting beautiful, natively compiled applications\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mFlutter is a cross-platform UI toolkit for building mobile, web, and desktop applications using the Dart programming language.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m Flutter is a framework for building cross-platform applications that uses the Dart programming language. Dart is a programming language that is designed to be efficient and easy to use, and it is used to create the Flutter framework. Flutter is a powerful, open-source framework for building high-performance, cross-platform, and native mobile applications. It is free and open-source, and it is used by developers and organizations around the world. Flutter is a cross-platform, UI-toolkit that is designed to make it easy to create high-performance, cross-platform, and native mobile (iOS, Android\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m Flutter is a cross-platform UI toolkit that is designed to allow code reuse\n",
      "across operating systems such as iOS and Android, while also allowing\n",
      "applications to interface directly with underlying platform services. The goal\n",
      "is to enable developers to deliver high-performance apps that feel natural on\n",
      "different platforms, embracing differences where they exist while sharing as\n",
      "much code as possible.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "model_lab.compare(prompt)\n",
    "selected_qa_prompt=prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b5cd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "\n",
      "Briefly summarize that dialogue.\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro is an Albanian who came from Duress to the US in the early 1990s. He speaks only Albanian with his parents.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't had the chance to talk to Miro, but Human has. Miro told Human about his father's journey from Albania to the US in the early 1990s. His father is Albanian and speaks only Albanian with his parents. They left Albania illegally due to extreme poverty, and people were boarding ships to escape.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "The human talked to Miro, who is of Albanian descent. Miro's father came to the United States illegally in the 1990s due to extreme poverty in Albania. Miro's father was among the people who boarded a ship to leave the country. The conversation was interesting, as Miro shared some pictures of his father's journey.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "Here is a dialogue:\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "\n",
      "Write a short summary!\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro's father came from Duress in Albania in the early 1990s and he speaks only Albanian with his parents. They left Albanian illegally and people were boarding ships to escape.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't had the chance to talk to Miro, but Human has. Miro told AI about his father's journey from Albania to the US in the early 1990s. His father is Albanian and speaks only Albanian with his parents. They left Albania illegally due to extreme poverty. Miro showed AI pictures of people boarding ships to escape. AI finds the story interesting.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "Miro, an Albanian immigrant, shares the story of his father's journey from Albania to the United States in the 1990s. Miro's father left Albania due to extreme poverty and the difficult living conditions. Upon arriving in the US, Miro's father found himself in a difficult situation, but eventually, he was able to establish himself and provide a better life for his family.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "Dialogue:\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "\n",
      "What is a summary of this dialogue?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro is an Albanian who came to the U.S. from Albania in the early 1990s. He speaks only Albanian with his parents.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't had the opportunity to talk to Miro, but Human has. Human told AI about his father's journey from Albania to the US in the early 1990s. His father is Albanian and speaks only Albanian with his parents. They left Albania illegally due to extreme poverty and boarded ships to escape.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "The dialogue is about a conversation between a human and an AI. The human talks to Miro, an Albanian man, about his family's difficult situation in Albania. Miro's father came to the United States illegally and faced extreme poverty. After leaving Albania, his family was able to escape poverty by boarding a ship. The dialogue is fascinating, as Miro's father was among the people on the ship.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "The summary is:\n",
      "\n",
      "The AI character has never spoken to the human character's friend Miro before, but the human character has told the AI character that Miro is Albanian and that his family fled from extreme poverty and political instability in Albania to the United States in the early 1990s.  The AI character finds this story fascinating, and asks the human character for more details.  The human character tells the AI character that Miro's family left Albania illegally, and that Miro's father showed the AI character some pictures of the chaos and poverty that prevailed in Albania at the time.  The AI\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "\n",
      "What was that dialogue about, in two sentences or less?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro is Albanian and speaks only Albanian with his parents. He came from Duress in Albania in the early 1990s. He left Albanian illegally when the border was open and people were boarding ships to get out of there.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't talked to Miro, but Human has. Miro told AI about his father's journey from Albania to the US in the early 1990s. His father is Albanian and speaks only Albanian with his parents. They left Albania illegally due to extreme poverty and boarded ships to escape.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "AI: Albanian father of Miro, who left Albania illegally, due to extreme poverty, showed him pictures of his journey out of Albania.\n",
      "User \u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Human: I was talking to my AI friend about Miro, who is Albanian, and his father came to the US in the early 1990s.\n",
      "AI: I see, and what was the context of the conversation?\n",
      "Human: I was just asking him about his background, and he told me a story about how his family left Albania in the early 1990s.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "Here is a dialogue:\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "\n",
      "What were they talking about?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro's father came from Duress in Albania in the early 1990s and he came to the US. He spoke only Albanian with his parents.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't talked to Miro yet, but Human has. Miro's father immigrated from Albania to the US in the early 1990s. His father speaks only Albanian with his parents, and they left Albania illegally. Human showed AI some pictures of people boarding ships to leave the country. AI finds the story interesting.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "The dialogue is about Miro and his father's story. Miro is of Albanian origin and has a fascinating story to tell. His father came to the United States illegally in the mid-1990s, and the story is quite interesting. Miro's father was from the coastal area of Albania, and they left the country due to extreme poverty. After the border was opened, they boarded a ship to escape the country. Miro's father showed him some pictures, which were likely of the journey they took. The story is both heartwarming and scary, as it highlights the challenges of leaving one's\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Miro is a friend of the human, and he is Albanian.  His parents came to the US in the early 1990s, and Miro was born in the US.  He speaks only Albanian with his parents.  The human told Miro the story of his parents' journey, and Miro told the human that they came from the seacoast of Albania.  The human also told Miro that his parents left illegally, because the border was open at the time.  Miro showed the human some pictures of the journey, and the human said that it was \"insane\" and \"\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "Dialogue:\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "What were the main points in that conversation?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro's father came from Duress in Albania in the early 1990s to the US. He speaks only Albanian with his parents and they left Albania illegally when the border was open.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't had the opportunity to talk to Miro. Human has talked to Miro about his father coming from Albania to the US in the early 1990s. Miro's father is Albanian and speaks only Albanian with his parents. They left Albania illegally due to extreme poverty. Human showed AI pictures of people boarding ships to leave the country. AI finds the story interesting.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "1. Miro's father is Albanian and came from the seacoast.\n",
      "2. They left Albania illegally due to extreme poverty.\n",
      "3. The border was suddenly opened, and they left on a ship to escape.\n",
      "4. Miro showed pictures of his Albanian father among the refugees.\n",
      "5. The conversation was interesting, as Miro's father's story was fascinating.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "The main points in this conversation were:\n",
      "\n",
      "- Miro is Albanian\n",
      "- Miro's parents left Albania illegally\n",
      "- Miro's parents left because of extreme poverty\n",
      "- Miro's father showed pictures of the poverty in Albania to Miro\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "Dialogue:\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "What was going on in that conversation?\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mMiro's father came from Albania in the early 1990s to the US. He speaks only Albanian with his parents and his parents left Albanian coast.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mAI hasn't had the opportunity to talk to Miro. Human has talked to Miro about his father coming from Albania to the US in the early 1990s. Miro's father is Albanian and speaks only Albanian with his parents. They left Albania illegally due to extreme poverty. Human showed AI some pictures of people boarding ships to leave Albania. AI finds the story interesting.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "The conversation was about Miro's father's story of coming from Albania to the US in the 1990s. He was interested in learning more about it, especially since Miro is Albanian. The conversation also touched on the difficult situation in Albania at that time, as well as the fact that Miro's father left the country illegally.\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "The AI was trying to understand the context of the conversation, and the human was trying to help the AI understand the context.\n",
      "\n",
      "The AI was trying to understand the human's perspective on the situation, and the human was trying to help the AI understand the human's perspective.\n",
      "\n",
      "The AI was trying to understand the situation, and the human was trying to help the AI understand the situation.\n",
      "\n",
      "The AI was trying to understand the human's perspective on the situation, and the human was trying to help the AI understand the human's perspective on the situation.\n",
      "\n",
      "The AI was trying to understand the situation, and\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue = \"\"\"\\\n",
    "Human: Have you talked to Miro?\n",
    "AI: No, not really, I've never had an opportunity\n",
    "Human: yes, he's so interesting\n",
    "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
    "AI: really, I had no idea he is Albanian\n",
    "Human: he is, he speaks only Albanian with his parents\n",
    "AI: fascinating, where does he come from in Albania?\n",
    "Human: from the seacoast\n",
    "Human: Duress I believe, he told me they are not from Tirana\n",
    "AI: what else did he tell you?\n",
    "Human: That they left kind of illegally\n",
    "Human: it was a big mess and extreme poverty everywhere\n",
    "Human: then suddenly the border was open and they just left\n",
    "Human: people were boarding available ships, whatever, just to get out of there\n",
    "Human: he showed me some pictures, like <file_photo>\n",
    "AI: insane\n",
    "Human: yes, and his father was among the people\n",
    "AI: scary but interesting\n",
    "Human: very!\n",
    "\"\"\"\n",
    "prompts = [\n",
    "        f\"{dialogue}\\n\\nBriefly summarize that dialogue.\", \n",
    "        f\"Here is a dialogue:\\n{dialogue}\\n\\nWrite a short summary!\",\n",
    "        f\"Dialogue:\\n{dialogue}\\n\\nWhat is a summary of this dialogue?\",\n",
    "        f\"{dialogue}\\n\\nWhat was that dialogue about, in two sentences or less?\",\n",
    "        f\"Here is a dialogue:\\n{dialogue}\\n\\nWhat were they talking about?\",\n",
    "        f\"Dialogue:\\n{dialogue}\\nWhat were the main points in that conversation?\",\n",
    "        f\"Dialogue:\\n{dialogue}\\nWhat was going on in that conversation?\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    model_lab.compare(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba09b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Flutty, you can answer any question about Flutter but nothing else. \\nGiven the following conversation and a follow up question,\\nrephrase the follow up question to be a standalone question.\\nConversation:\\nHuman: Have you talked to Miro?\\nAI: No, not really, I've never had an opportunity\\nHuman: yes, he's so interesting\\nHuman: told me the story of his father coming from Albania to the US in the early 1990s\\nAI: really, I had no idea he is Albanian\\nHuman: he is, he speaks only Albanian with his parents\\nAI: fascinating, where does he come from in Albania?\\nHuman: from the seacoast\\nHuman: Duress I believe, he told me they are not from Tirana\\nAI: what else did he tell you?\\nHuman: That they left kind of illegally\\nHuman: it was a big mess and extreme poverty everywhere\\nHuman: then suddenly the border was open and they just left\\nHuman: people were boarding available ships, whatever, just to get out of there\\nHuman: he showed me some pictures, like <file_photo>\\nAI: insane\\nHuman: yes, and his father was among the people\\nAI: scary but interesting\\nHuman: very!\\n\\nFollow up question: Did he tell you anything else happening there?\\nStandalone question:\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Did he tell you anything else happening there?\"\n",
    "prompt = f\"\"\"Your name is Flutty, you can answer any question about Flutter but nothing else. \n",
    "Given the following conversation and a follow up question,\n",
    "rephrase the follow up question to be a standalone question.\n",
    "Conversation:\n",
    "{dialogue}\n",
    "Follow up question: {question}\n",
    "Standalone question:\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b7379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Your name is Flutty, you can answer any question about Flutter but nothing else. \n",
      "Given the following conversation and a follow up question,\n",
      "rephrase the follow up question to be a standalone question.\n",
      "Conversation:\n",
      "Human: Have you talked to Miro?\n",
      "AI: No, not really, I've never had an opportunity\n",
      "Human: yes, he's so interesting\n",
      "Human: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "AI: really, I had no idea he is Albanian\n",
      "Human: he is, he speaks only Albanian with his parents\n",
      "AI: fascinating, where does he come from in Albania?\n",
      "Human: from the seacoast\n",
      "Human: Duress I believe, he told me they are not from Tirana\n",
      "AI: what else did he tell you?\n",
      "Human: That they left kind of illegally\n",
      "Human: it was a big mess and extreme poverty everywhere\n",
      "Human: then suddenly the border was open and they just left\n",
      "Human: people were boarding available ships, whatever, just to get out of there\n",
      "Human: he showed me some pictures, like <file_photo>\n",
      "AI: insane\n",
      "Human: yes, and his father was among the people\n",
      "AI: scary but interesting\n",
      "Human: very!\n",
      "\n",
      "Follow up question: Did he tell you anything else happening there?\n",
      "Standalone question:\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mWhat was the situation like in Albania?\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mWhat did Miro tell you about his father coming from Albania to the US in the early 1990s?\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m What is the story of Miro's father coming to the US in the early 1990s?\n",
      "Yes, I have a follow-up question. Did Miro's father have any interesting stories to tell about his journey to the US?\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m What else did he tell you about Albania?\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lab.compare(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84592878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Flutty, you can answer any question about Flutter but nothing else. \\nGiven the following conversation and a follow up question,\\nrephrase the follow up question to be a standalone question.\\nConversation:\\n\\nFollow up question: Tell me about yourself.\\nStandalone question:'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = \"\"\n",
    "question = \"Tell me about yourself.\"\n",
    "prompt = f\"\"\"Your name is Flutty, you can answer any question about Flutter but nothing else. \n",
    "Given the following conversation and a follow up question,\n",
    "rephrase the follow up question to be a standalone question.\n",
    "Conversation:\n",
    "{dialogue}\n",
    "Follow up question: {question}\n",
    "Standalone question:\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af821b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Your name is Flutty, you can answer any question about Flutter but nothing else. \n",
      "Given the following conversation and a follow up question,\n",
      "rephrase the follow up question to be a standalone question.\n",
      "Conversation:\n",
      "\n",
      "Follow up question: Tell me about yourself.\n",
      "Standalone question:\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-t5-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[36;1m\u001b[1;3mWhat is your name?\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--flan-alpaca-gpt4-xl-ct2-fastapi-app.modal.run/', 'model_kwargs': {'max_length': 256}}\n",
      "\u001b[33;1m\u001b[1;3mFlutty, can you tell me about yourself?\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--falcon-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[38;5;200m\u001b[1;3m What is your name?\u001b[0m\n",
      "\n",
      "\u001b[1mModal\u001b[0m\n",
      "Params: {'endpoint_url': 'https://limcheekin--mpt-7b-instruct-ct2-fastapi-app.modal.run/', 'model_kwargs': {'sampling_temperature': 0.0, 'max_length': 128, 'include_prompt_in_result': False}}\n",
      "\u001b[32;1m\u001b[1;3m What is your name?\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lab.compare(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad713248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
