{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTranslate2\n",
    "\n",
    "## Overview\n",
    "\n",
    "CTranslate2 is a C++ and Python library for efficient inference with Transformer models. The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.\n",
    "\n",
    "I try to use it for Flan-T5 models by refer to the sample codes from https://opennmt.net/CTranslate2/guides/transformers.html#t5\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU ctranslate2 transformers[torch] sentencepiece"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model\n",
    "### Use Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ctranslate2 \n",
    "#model_id = \"google/flan-t5-small\"\n",
    "#ct = ctranslate2.converters.TransformersConverter(model_name_or_path=model_id)\n",
    "#ct.convert(output_dir=\"google/flan-t5-small-ct2\", force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ct2-transformers-converter --model google/flan-t5-small --output_dir google/flan-t5-small-ct2 --quantization int8 --force\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctranslate2\n",
    "import transformers\n",
    "\n",
    "translator = ctranslate2.Translator(\"google/flan-t5-xl-ct2\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/flan-t5-xl-ct2\")\n",
    "\n",
    "input_text = \"translate English to German: The house is wonderful.\"\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(input_text))\n",
    "\n",
    "results = translator.translate_batch([input_tokens])\n",
    "\n",
    "output_tokens = results[0].hypotheses[0]\n",
    "output_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(output_tokens))\n",
    "\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What is AI? Tell me more about it.\"\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(input_text))\n",
    "\n",
    "results = translator.generate_tokens(input_tokens)\n",
    "\n",
    "END_TOKEN = '</s>'\n",
    "for i, result in enumerate(results):\n",
    "    if result.token != END_TOKEN:\n",
    "        if i == 0:\n",
    "            print(result.token.replace('▁', ''), end='')\n",
    "        else:    \n",
    "            print(result.token.replace('▁', ' '), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What is AI? Tell me more about it.\"\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(input_text))\n",
    "\n",
    "results = translator.translate_iterable([input_tokens])\n",
    "\n",
    "for result in results:\n",
    "    for hypothesis in result.hypotheses:\n",
    "        print(tokenizer.decode(tokenizer.convert_tokens_to_ids(hypothesis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "sampling_temperature was transfered to model_kwargs.\n",
      "                    Please confirm that sampling_temperature is what you intended.\n",
      "max_decoding_length was transfered to model_kwargs.\n",
      "                    Please confirm that max_decoding_length is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from custom.llms.ctranslate2 import Ct2Translator\n",
    "llm = Ct2Translator(model_path=\"../ct2/fastchat-t5-3b-ct2\", \n",
    "                    #tokenizer_path=\"google/flan-t5-xl-ct2\", \n",
    "                    sampling_temperature=0.0, max_decoding_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is AI?\n",
      "\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence (AI) is a type of computer technology that uses algorithms and data to perform tasks that normally require human intelligence, such as problem solving and decision making. AI systems can be classified into two main categories based on their level of complexity and intelligence: machine learning and natural language processing (NLP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain.run(\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '../ct2/fastchat-t5-3b-ct2',\n",
       " 'tokenizer_path': '../ct2/fastchat-t5-3b-ct2',\n",
       " 'inter_threads': 1,\n",
       " 'compute_type': 'int8',\n",
       " 'model_kwargs': {'sampling_temperature': 0.0, 'max_decoding_length': 64}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm._identifying_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.T5Tokenizer.from_pretrained(\"google/flan-t5-xl-ct2\")\n",
    "tokenizer.convert_ids_to_tokens(tokenizer.encode(\"`\"))\n",
    "\n",
    "tokenizer.encode(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32105, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.T5Tokenizer.from_pretrained(\"../ct2/fastchat-t5-3b-ct2\")\n",
    "tokenizer.convert_ids_to_tokens(tokenizer.encode(\"`\"))\n",
    "tokenizer.encode(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
