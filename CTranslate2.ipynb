{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTranslate2\n",
    "\n",
    "## Overview\n",
    "\n",
    "CTranslate2 is a C++ and Python library for efficient inference with Transformer models. The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.\n",
    "\n",
    "I try to use it for Flan-T5 models by refer to the sample codes from https://opennmt.net/CTranslate2/guides/transformers.html#t5\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU ctranslate2 transformers[torch] sentencepiece"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model\n",
    "### Use Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ctranslate2 \n",
    "#model_id = \"google/flan-t5-small\"\n",
    "#ct = ctranslate2.converters.TransformersConverter(model_name_or_path=model_id)\n",
    "#ct.convert(output_dir=\"google/flan-t5-small-ct2\", force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ct2-transformers-converter --model google/flan-t5-small --output_dir google/flan-t5-small-ct2 --quantization int8 --force\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/limcheekin/My Passport/langchain-playground/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Haus ist wunderbar.\n"
     ]
    }
   ],
   "source": [
    "import ctranslate2\n",
    "import transformers\n",
    "\n",
    "translator = ctranslate2.Translator(\"google/flan-t5-xl-ct2\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/flan-t5-xl-ct2\")\n",
    "\n",
    "input_text = \"translate English to German: The house is wonderful.\"\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(input_text))\n",
    "\n",
    "results = translator.translate_batch([input_tokens])\n",
    "\n",
    "output_tokens = results[0].hypotheses[0]\n",
    "output_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(output_tokens))\n",
    "\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generally, the AI is a computer program that is programmed to recognize objects and perform certain actions on them."
     ]
    }
   ],
   "source": [
    "input_text = \"What is AI? Tell me more about it.\"\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(input_text))\n",
    "\n",
    "results = translator.generate_tokens(input_tokens)\n",
    "\n",
    "END_TOKEN = '</s>'\n",
    "for i, result in enumerate(results):\n",
    "    if result.token != END_TOKEN:\n",
    "        if i == 0:\n",
    "            print(result.token.replace('▁', ''), end='')\n",
    "        else:    \n",
    "            print(result.token.replace('▁', ' '), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is AI? Artificial Intelligence (AI) is the practice of artificial intelligence (AI) that uses computers and algorithms to perform tasks.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is AI? Tell me more about it.\"\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(input_text))\n",
    "\n",
    "results = translator.translate_iterable([input_tokens])\n",
    "\n",
    "for result in results:\n",
    "    for hypothesis in result.hypotheses:\n",
    "        print(tokenizer.decode(tokenizer.convert_tokens_to_ids(hypothesis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
